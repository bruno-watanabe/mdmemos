# 目的
- 分類問題の精度向上手法を習得
- データ圧縮の習熟
- 事前学習の習熟
- モデル評価法の習熟
- 単分類器とアンサンブル分類器のモデル評価

# 前提条件
- 分類問題
- 連続値があるためカテゴリ値に変更する必要あり
- 前提の仮定があるためその仮定が正しいかの検証も必要
- 名義変数が順序変数的扱われ方をされているため修正必要

# ストーリ
- パターン1
    - [x]散布図
    - [x]onehot法適用
    - [x]散布図
    - [x]特徴量エンジニアリング
    - [x]散布図
    - MLアルゴリズム
        - [x]単分類器-特徴重要度
            - Logistic
            - SVM
            - DecesionTree
            - RandomForest
            - NaiveBaise
            - k-mearns
        - アンサンブル
            - voting
                - rbfSVM
                - Logistic Regression
                - KNN
                - Randome Forest
            - banking
                - rbfSVM
                - Logistic Regression
                - KNN
                - Randome Forest
            - boosting
                - Logistic Regression
                - Randome Forest
            - stacking
                - rbfSVM
                - Logistic Regression
                - KNN
                - Randome Forest
                
    - モデル評価
        - [x]F1値
        - [x]ROC

    - パイプライン
- パターン2
    - 散布図
    - onehot法適用
    - 散布図
    - 特徴量エンジニアリング
    - 散布図
    - MLアルゴリズム
        - 単分類器
            - Logistic
            - SVM
            - DecesionTree
            - RandomForest
            - NaiveBaise
            - k-mearns
        - アンサンブル
            - voting
            - banking
            - boosting
            - stacking
    - ハイパーパラメータチューニング(特徴量エンジニアリングのが効果大)
        - grid search
        - baysianoptimization
        - Hyperopt
        - Optuna
    - モデル評価
        - ベースラインクラス分類モデル評価
        - F1値
        - ROC
        - Hppの評価
- パターン3
    - 散布図
    - onehot法適用
    - 散布図
    - 特徴量エンジニアリング
        - データ圧縮
    - 散布図
    - MLアルゴリズム
        - 単分類器
            - Logistic
            - SVM
            - DecesionTree
            - RandomForest
            - NaiveBaise
            - k-mearns
        - アンサンブル
            - voting
            - banking
            - boosting
            - stacking
    - ハイパーパラメータチューニング(特徴量エンジニアリングのが効果大)
        - grid search
        - baysianoptimization
        - Hyperopt
        - Optuna
    - モデル評価
        - ベースラインクラス分類モデル評価
        - F1値
        - ROC
        - Hppの評価

# データ前処理
- トレーニングデータとテストデータの結合-取り扱いを簡単にするため
- onehot法の適用
- 散布図表示-郡の確認

# 事前学習
- RFで特徴量の重要度確認
- 特徴量の寄与度を早期に解釈

# データ圧縮
- PCA vs LDA vs KPCA

---

# 分類問題適用
- Logistic
- SVM
- DecesionTree
- RandomForest
- NaiveBaise
- k-mearns

# アンサンブル学習
- voting
- banking
- boosting
- stacking

---

# モデル評価
- ベースラインクラス分類モデル評価
- F1値
- ROC
- Hppの評価

---

# パイプライン

# NN分類問題