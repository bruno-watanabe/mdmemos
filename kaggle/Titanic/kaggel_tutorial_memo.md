# Kernel
``` 概要:
Kaggleには、Kernelと呼ばれるブラウザ上の実行環境が用意されています。言語としては現在、Python3とRが対応しています。それぞれScript形式かNotebook形式を選択可能です。
```
- 公開したい場合は<br>
サイドバー＞Settings＞Sharing>Public

- Kernel操作

| cmd | deic|
| --- | --- |
| +Code| コード追加 |
| +MarkDown| MD追加 |
| SHIFT+ENTER | コード実行 |
| Commit | Kernel全体を実行 |
| Open | 実行後のkernelを確認する |
| Output | Kernelでの予測結果が「submission.csv」というファイルで保存されています|
| Submit to Competition | ファイルをsubmit |

※詳細はJupyter Notebook 使い方で調べる

# コンペ(Titanic)のチュートリアル

主な流れ：
1. パッケージの読み込み
2. データの読み込み
3. 特徴量エンジニアリング
4. 機械学習アルゴリズムの学習・予測
5. submit（提出)


## 1. パッケージの読み込み
```
%matplotlib inline
import numpy as np
import pandas as pd
```

## 2. データの読み込み
※コンペのデータ説明を読み込んでから実データを見てデータを俯瞰する
- データの読み込み
```
train = pd.read_csv("../input/train.csv")
test = pd.read_csv("../input/test.csv")
gender_submission = pd.read_csv("../input/gender_submission.csv")
```
- 実データの簡単なチェック
```
gender_submission.head()
train.head()
test.head()
```
test.csvには目的変数の列が存在しない

考察:
```
Name, Sexなどは文字列で格納されており、そのままでは機械学習アルゴリズムの入力にすることはできません。
機械学習アルゴリズムが扱える数値の形式に変換していく必要があります。
Nanというのは、データの欠損です。こうした欠損値は、一部の機械学習アルゴリズムではそのまま扱うこともできますが、平均値など代表的な値で穴埋めする場合も多いです


上記よりデータを加工する必要があると判断-この一連の処理を特徴量エンジニアリングという
```

## 3. 特徴量エンジニアリング

- 「train.csv」と「test.csv」をまとめて扱う方が都合が良いので、dataという形でこの段階で結合
- 各ラベルの欠損値数確認 ->data.isnull().sum()
- 分類への寄与の高いものの山をはる ->直感的にわかりやすいラベルで分類してみるとか
- 文字列データは数値データに変換する->onehot法, 0;1;2埋め, 平均値埋め, 標準偏差を考慮した乱数で穴埋め等
- 見繕ったデータラベルでデータをまとめる

## 4. 機械学習アルゴリズム
- 機械学習アルゴリズムのパッケージ読み込み
- 予測器の設定(ハイパーパラメータ設定)
- 予測器の学習
- テストデータを予測
- 提出用フォーマットを出力

# スコア向上テクニック
## 再現性
```
「再現性がある」とは、何度実行しても同じ結果が得られることです。Kaggleで言うと、同一のスコアが得られると言い換えても良いでしょう。

再現性がないと、実行ごとに異なるスコアが得られてしまいます。今後、特徴量エンジニアリングなどでスコアの向上を試みても、予測モデルが改善されたか否かを正しく判断できなくなる問題が生じます
```
- 機械学習アルゴリズムの大半は乱数を利用するので、再現性を担保するためにはseedを設定しておかなければなりません。


## 特徴量エンジニアリング
- 仮説から新しい特徴量を作る
    - 予測精度に寄与しそうな仮説を立てる
    - 可視化を実施する
        - 予測精度に寄与する仮説を見つけるため
        - 仮説が正しいかを検証するため

※仮説を立てるためのドメイン知識がない場合は:
```
ドメイン知識がない場合は、まずは仮説を立てるための探索的なデータ分析を実施することになるでしょう。いろいろな軸でデータを眺め、予測精度に寄与しそうな仮説を立てるのが目的になります。
```

## 精度アップアルゴリズム
- 勾配ブースティングという機械学習アルゴリズムの「LightGBM」というパッケージ
- アンサンブル学習

## ハイパーパラメータの調整
```
機械学習アルゴリズムの振る舞いはハイパーパラメータという値で制御されます。もちろん、ハイパーパラメータの値次第で予測結果は変わり得ます。
```
- チューニングツールを使う
    - Grid search
    - Bayesian Optimization
    - Hyperopt
    - Optuna
- 手動で調整

※上記のツールでのハイパーパラメータ調整が現実的な時間で終わらない問題もあり
```
ハイパーパラメータでのスコアの上がり幅は特徴量エンジニアリングで良い特徴量を見つけた場合に劣るので、あまり時間をかけずに手動で微調整をする場合も多いように感じます
チューニングツールを使うにせよ、手動で調整するにせよ、機械学習アルゴリズムをブラックボックス的に利用するのではなく、ハイパーパラメータを正しく理解することが非常に大切です。
```

## Validation
- ホールドアウト検証<br>
トレーニングデータから一部検証用データとして抽出して活用する
- Closs Validation
ホールドアウト法ベースに検証データ切り分けと検証を複数回行うこと

# 始め方
- ベースラインとなるKernelを探す
    - Most Votes
    - EDAが参考にしやすい
- 本記事の内容を参考に、ベースラインを改善する